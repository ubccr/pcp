#!/usr/bin/env python
#
# Copyright (c) 2015 Martins Innus
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
# or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
# for more details.
#
#
# tacc_stats reading portion derived from the pickler code for tacc_stats from:
# https://github.com/TACC/tacc_stats


import datetime, numpy, os, sys, gzip, getopt
import amd64_pmc, intel_snb
import math

from pcp import pmi
from pcp import pmapi
import cpmapi as c_api

# dict that holds the mapping from tacc_stats to pcp metrics
# generated by the generateT2Pmappings.py script
import pcpmapping

# Support older python
class myGzipFile(gzip.GzipFile):
    def __enter__(self):
        if self.fileobj is None:
            raise ValueError("I/O operation on closed GzipFile object")
        return self

    def __exit__(self, *args):
        self.close()


class SchemaEntry(object):
    '''Individual elements of the tacc_stats schema
    '''

    __slots__ = ('key', 'index' )

    def __init__(self, i, s):
        opt_lis = s.split(',')
        self.key = opt_lis[0]
        self.index = i
    # Don't use the fields, just validate that the schema is correct
        for opt in opt_lis[1:]:
            if len(opt) == 0:
                continue
            elif opt[0] == 'C':
                continue
            elif opt[0] == 'E':
                continue
            elif opt[0:2] == 'W=':
                continue
            elif opt[0:2] == 'U=':
                continue
            else:
                raise ValueError("unrecognized option `%s' in schema entry spec `%s'\n", opt, s)

    def __eq__(self, other):
        return isinstance(other, self.__class__) and \
               all(self.__getattribute__(attr) == other.__getattribute__(attr) \
                   for attr in self.__slots__)

    def __ne__(self, other):
        return not self.__eq__(other)

    def __repr__(self):
        lis = [] # 'index=%d' % self.index
        return '(' + ', '.join(lis) + ')'


class Schema(dict):
    '''Dictionary of schema lists. Dict keyed on type. Array elements are the metrics.
    '''

    def __init__(self, desc):
        dict.__init__(self)
        self.desc = desc
        self._key_list = []
        self._value_list = []
        for i, s in enumerate(desc.split()):
            e = SchemaEntry(i, s)
            dict.__setitem__(self, e.key, e)
            self._key_list.append(e.key)
            self._value_list.append(e)

    def __iter__(self):
        return self._key_list.__iter__()

    def __repr__(self):
        return '{' + ', '.join(("'%s': %s" % (k, repr(self[k]))) \
                               for k in self._key_list) + '}'

    def _notsup(self, s):
        raise TypeError("'Schema' object does not support %s" % s)

    def __delitem__(self, k, v):
        self._notsup('item deletion')

    def pop(self, k, d=None):
        self._notsup('removal')

    def popitem(self):
        self._notsup('removal')

    def setdefault(self, k, d=None):
        self._notsup("item assignment")

    def update(self, **args):
        self._notsup("update")

    def items(self):
        return zip(self._key_list, self._value_list)

    def iteritems(self):
        for k in self._key_list:
            yield (k, dict.__getitem__(self, k))

    def iterkeys(self):
        return self._key_list.__iter__()

    def itervalues(self):
        return self._value_list.__iter__()

    def keys(self):
        return self._key_list

    def values(self):
        return self._value_list


class TaccStatsReader(object):
    '''Read the header and data and provide a stats file that is:
    stats[type][dev][2d numpy array]
    '''

    def __init__(self):
        self.schemas = {}
        self.times = []
        self.raw_stats = {}
        self.stats = {}
        self.timedict={}
        #self.marks = {}

        self.timestamp = None
        self.filename = None
        self.fileline = None
        self.hostname = ""

        self.SF_SCHEMA_CHAR = '!'
        self.SF_DEVICES_CHAR = '@'
        self.SF_COMMENT_CHAR = '#'
        self.SF_PROPERTY_CHAR = '$'
        self.SF_MARK_CHAR = '%'

    def error(self, fmt, *args):
        msg = fmt % args
        sys.stderr.write(msg)

    def read_stats_file_header(self, fp):
        file_schemas = {}
        for line in fp:
            self.fileline += 1
            try:
                c = line[0]
                if c == self.SF_SCHEMA_CHAR:
                    type_name, schema_desc = line[1:].split(None, 1)
                    schema = self.get_schema(type_name, schema_desc)
                    if schema:
                        file_schemas[type_name] = schema
                    else:
                        self.error("file `%s', type `%s', schema mismatch desc `%s'\n",
                                   fp.name, type_name, schema_desc)
                elif c == self.SF_PROPERTY_CHAR:
                    if "hostname" in line:
                        self.hostname = line.split()[1]
                    pass
                elif c == self.SF_COMMENT_CHAR:
                    pass
                else:
                    break
            except Exception as exc:
                self.error("file `%s', caught `%s' discarding line `%s'\n",
                           fp.name, exc, line)
                break
        return file_schemas


    def read_stats_file(self, fp):

        self.filename = fp.name
        self.fileline = 0

        self.file_schemas = self.read_stats_file_header(fp)
        if not self.file_schemas:
            self.error("file `%s' bad header on line %s\n", self.filename, self.fileline)
            return

        for line in fp:
            self.fileline += 1
            self.parse(line.strip())


    def parse(self, line):
        if len(line) < 1:
            return

        ch = line[0]

        if ch.isdigit():
            self.processtimestamp(line)
        elif ch.isalpha():
            self.processdata(line)
        elif ch == self.SF_COMMENT_CHAR:
            pass
        elif ch == self.SF_MARK_CHAR:
            #print "Skipping mark for now"
            pass
        else:
            print "Unrecognised character \"{}\"".format(line)
            pass

    def processtimestamp(self,line):
        '''Read in a timestamp line
        '''

        recs = line.strip().split(" ")
        self.timestamp = float(recs[0])
    #SAVE to deal with job info later
        #jobs = recs[1].strip().split(",")
        self.times.append( self.timestamp )

    def processdata(self,line):
        '''Read in a metric line
        '''

        type_name, dev_name, rest = line.split(None, 2)
        schema = self.file_schemas.get(type_name)
        if not schema:
            self.error("file `%s', unknown type `%s', discarding line `%s'\n",
                    self.filename, type_name, self.fileline)
            return

        vals = numpy.fromstring(rest, dtype=numpy.uint64, sep=' ')
        if vals.shape[0] != len(schema):
            self.error("file `%s', type `%s', expected %d values, read %d, discarding line `%s'\n",
                   self.filename, type_name, len(schema), vals.shape[0], self.fileline)
            return

        type_stats = self.raw_stats.setdefault(type_name, {})
        dev_stats = type_stats.setdefault(dev_name, [])
        dev_stats.append((self.timestamp, vals))

    def gather_stats(self, infile):
        '''Read the tacc_stats file.  They are gziped text files with a schema header
        '''

        try:
            with myGzipFile(infile) as file:
                self.read_stats_file(file)
        except IOError as ioe:
            self.error("read error for file %s\n", infile)

        return self.raw_stats

    def get_schema(self, type_name, desc=None):
        schema = self.schemas.get(type_name)
        if schema:
            if desc and schema.desc != desc:
                # ...
                return None
        elif desc:
            schema = self.schemas[type_name] = Schema(desc)
        return schema

    def process_dev_stats(self, type_name, schema, dev_name, raw):
        '''raw is a list of pairs with car the timestamp and cdr a 1d
           numpy array of values.
        '''

        m = len(self.times)
        n = len(schema)
        A = numpy.zeros((m, n), dtype=numpy.uint64) # Output.

        k = len(raw)

        # len(raw) may not be equal to m (if metrics/devs come and go), so we fill out A from 0
        # And keep track of this metric/instance time series

        # Dict so we can back-reference the times when building the pcp log
        timekey = "%s%s" % (type_name, dev_name)
        self.timedict[timekey]={}

        for i in xrange(0, k):
            A[i] = raw[i][1]
            self.timedict[timekey][raw[i][0]] = i

        return A
    
    def process_stats(self):
        '''Not much more than data copying in the first part, but the amd and intel
        routines below require the data in a certain format
        '''

        for type_name, raw_type_stats in self.raw_stats.iteritems():
            stats = self.stats[type_name] = {}
            schema = self.schemas[type_name]
            for dev_name, raw_dev_stats in raw_type_stats.iteritems():
                stats[dev_name] = self.process_dev_stats( type_name, schema,
                                                             dev_name, raw_dev_stats)
        del self.raw_stats

    # Convert the counter metrics from just register labels to a readable form
        amd64_pmc.process_job(self)
        intel_snb.process_job(self)

        return True


class TaccStats2PCPEngine(object):
    def __init__(self, tsdata):
        self.tsdata = tsdata
        self.stats = tsdata.stats
        # Generated instance numbers for indoms where they aren't obvious from the iname
        self.gen_inst = {}
    
    def get_metric_def(self, type, dev, metric):
        '''For a given  ( type,dev,metric ) return the (pcp name, pmid, type, sem, indom, units) '''
    
        p_name = pcpmapping.pcpmappingdict[type][metric]['name']
        p_pmid = pcpmapping.pcpmappingdict[type][metric]['pmid']
        p_type = pcpmapping.pcpmappingdict[type][metric]['type']
        p_sem = pcpmapping.pcpmappingdict[type][metric]['sem']
        p_indom = pcpmapping.pcpmappingdict[type][metric]['indom']
        if( p_indom == -1):
            p_indom = c_api.PM_IN_NULL
        p_units, p_scale = pmapi.pmContext.pmParseUnitsStr( pcpmapping.pcpmappingdict[type][metric]['units'] )
    
        # Convert the name if necesarry
        p_name, item_offset = self.metric_name_convert( type, dev, p_name )
        # Need a better fcn for the pmid change
        p_pmid += item_offset
    
        return ( p_name, p_pmid, p_type, p_sem, p_indom, p_units )

    def metric_name_convert( self, type, dev, pcpname ):
        ''' Replace any %d in the name with the appropriate value.  Mostly affects
            perfctr metrics that encode the metric and instance in the dev
            field for tacc_stats. Also return the substituted value.
        '''
        met_part = 0

        if "%" in pcpname and "/" in dev:
            inst_part, met_part = dev.split("/")
            pcpname = pcpname % int(met_part)

        return pcpname, int(met_part)


    def get_metric_value(self, type, dev, tmet, tindex, time_idx ):
        pcpname = pcpmapping.pcpmappingdict[type][tmet]['name']

        # Array of metrics for this [type][dev][time]
        metric_vals = self.stats[type][dev][time_idx]
        cur_value = 0;

        cur_value = metric_vals[tindex]

        # Do we need to convert the units from tacc_stats to pcp
        if 'valconv' in pcpmapping.pcpmappingdict[type][tmet]:
            cur_value = pcpmapping.pcpmappingdict[type][tmet]['valconv'](cur_value)

        # If there is a %d in the pcpname, construct it from the metric/dev as appropriate
        # We only need the name here
        pcpname = self.metric_name_convert( type, dev, pcpname )[0]

        return (pcpname, cur_value)

    def itermetrics(self, timestamp):
        print "Itermetrics called at %d" % timestamp
        # Return the metrics at this timestamp
        for type in self.stats:
            # If we know how to deal with this metric
            if type in pcpmapping.pcpmappingdict:
                sample_time = self.tsdata.times[ timestamp ]
                # And there is a value for it at this time step
                for dev in self.stats[type]:
                    # Instances could come and go (infiniband or fs could go up and down), so need to check each one
                    if sample_time in self.tsdata.timedict["%s%s" % (type, dev)]:
                        time_idx = self.tsdata.timedict["%s%s" % (type, dev)][sample_time]
                        if type not in self.tsdata.schemas:
                            # Should never happen is the mapping and schema are in sync
                            print "Error: %s not in schema" % type

                        schema = self.tsdata.schemas[type]
                        # The schema tells us the mapping from array index to tacc_stats metric name
                        for e in schema.itervalues():
                            tmet = e.key
                            tindex = e.index

                            # If we know how to deal with this metric
                            if tmet not in  pcpmapping.pcpmappingdict[type]:
                                continue
                            
                            pcpname, cur_value = self.get_metric_value( type, dev, tmet, tindex, time_idx )

                            yield ( type, dev, tmet, pcpname, cur_value )

    def get_instance_def(self, type, dev, metric):
        '''For a given (type,dev,metric) return the ( inst, iname )'''

        inst = 0;
        iname = ""
        if "inst_pattern" in pcpmapping.pcpmappingdict[type][metric]:
            # Need to construct the inst and iname parameters from the dev
            inst_pattern = pcpmapping.pcpmappingdict[type][metric]['inst_pattern']
            iname_pattern = pcpmapping.pcpmappingdict[type][metric]['iname_pattern']
            # Might be the dev directly or the X in X/Y for perfctrs
            inst_part = None
            if "/" in dev:
                inst_part, met_part = dev.split("/")
            else:
                inst_part = int(dev)

            inst = int( inst_pattern % int(inst_part) )
            iname = iname_pattern % int(inst_part)
        elif "inst" in pcpmapping.pcpmappingdict[type][metric]:
            # The instance is specified in the mapping file
            inst = int( pcpmapping.pcpmappingdict[type][metric]['inst'] )
            iname = pcpmapping.pcpmappingdict[type][metric]['iname']
        elif dev.isdigit():
            # The device is numeric, so just use that
            inst = int(dev)
            iname = dev
        elif dev == "-":
            print "Got '-' instance for type %s, shouldn't get here since c_api.PM_IN_NULL, check the mapping file" % type
            pass
        else:
            # We just use the dev as the iname and enumerate an inst
            # Keep track of the instance numbers for this type
            #
            # These will not be sequential, since this is called and incremented even if not added by caller
            if type not in self.gen_inst:
                self.gen_inst[type] = 0
            p_inst = self.gen_inst[type]
    
            inst = p_inst
            iname = dev
    
            p_inst +=1
            self.gen_inst[type] = p_inst
    
        return ( inst, iname)


class TaccStats2PCP(object):
    def __init__(self, argv):
        self.argv = argv
        self.tsreader = None
        self.pcpout = None
        self.ts2pcp = None

        self.infile = ''
        self.outdir = './'
        self.outfile = ''

        # Keep track of metrics we have added so they are only added once
        # Could be in the mapping multiple times due to instances
        self.added_metrics = {}
    
        # Keep track of instances so we only add each one once.
        self.added_instances = {}
    
        # Save the pcpname:dev string as an id to get iname for putvalue
        self.dev_inst = {}

    def print_mapping(self):
        for type in pcpmapping.pcpmappingdict:
            for dev in pcpmapping.pcpmappingdict[type]:
                print "%s , %s : %s" % (type, dev, pcpmapping.pcpmappingdict[type][dev]['name'])

    def dump_schema(self):
        for name, schema in self.tsreader.schemas.iteritems():
            for e in schema.itervalues():
                print "%s %s" % (name, e.key)

    def parse_opt(self):

        #global infile
        #global outdir
        #global outfile

        only_dump_schema = 0

        usage = '%s [-d <outdir>] [-o <outfile>] infile' % self.argv[0]

        try:
            opts, args = getopt.getopt(self.argv[1:],"hmsd:o:")
        except getopt.GetoptError:
            print usage
            sys.exit(2)
        for opt, arg in opts:
            if opt == '-h':
                print usage
                sys.exit()
            if opt == '-m':
                self.print_mapping()
                sys.exit()
            if opt == '-s':
                only_dump_schema = 1
            elif opt in ("-d"):
                self.outdir = arg
            elif opt in ("-o"):
                self.outfile = arg

        if len(args) == 1 and args[0] != '':
            self.infile = args[0]
        else:
            print usage
            sys.exit(2)

        if only_dump_schema:
            self.read_taccstats()
            self.dump_schema()
            sys.exit()


    def read_taccstats(self):
        self.tsreader = TaccStatsReader()
        self.tsreader.gather_stats(self.infile)

    def process_taccstats(self):
        self.tsreader.process_stats()
    
    def init_pcp(self):
        startsec = self.tsreader.times[0]
        timelabel = datetime.datetime.fromtimestamp( startsec ).strftime("%Y%m%d.%H.%M")
    
        filelabel = self.outdir + '/'
    
        if self.outfile != '':
            filelabel += self.outfile
        else:
            filelabel += timelabel
    
        self.pcpout = pmi.pmiLogImport( filelabel )
        self.pcpout.pmiSetHostname(self.tsreader.hostname)
        self.pcpout.pmiSetTimezone("UTC")
        
    def setup_mappings(self):
    
        allstats = self.tsreader.stats
    
        # Add the metrics & instances
        # Only in the union of allstats & pcpmapping
    
        self.ts2pcp = TaccStats2PCPEngine( self.tsreader )
    
        for type in allstats:
            if type in pcpmapping.pcpmappingdict:
                # Need to loop through the devs becasue some metric names are encoded there (perf counters)
                for dev in allstats[type]:
                    for metric in pcpmapping.pcpmappingdict[type]:

                        # Metrics
                        ( p_name, p_pmid, p_type, p_sem, p_indom, p_units ) = self.ts2pcp.get_metric_def( type, dev, metric )
                        if p_name not in self.added_metrics:
                            #print "Adding metric: %s" % p_name
                            self.pcpout.pmiAddMetric( p_name, p_pmid, p_type, p_indom, p_sem, p_units )
                            self.added_metrics[p_name] = 1

                        # Instances
                        if p_indom != c_api.PM_IN_NULL:
    
                            ( inst, iname) = self.ts2pcp.get_instance_def(type, dev, metric)
    
                            # Save the instance for each type, metric, dev set to use later for putValue.  Need all 3 due to all the possible mappings (load)
                            self.dev_inst[ "%s:%s:%s" % (type, dev, metric) ] = iname
    
                            # But on the pcp side, we only need it once per indom/iname pair
                            instance_id = "%d:%s" % (p_indom, iname)
                            if instance_id not in self.added_instances:
                                self.added_instances[instance_id] = iname
                                self.pcpout.pmiAddInstance(p_indom, iname, inst)
    
    
    def write_metrics(self):

        m = len(self.tsreader.times)
        # Loop through all the times
        for i in xrange(0, m):
            #print "Loop %d at time : %f" % (i, self.tsreader.times[i])
            for type, dev, tmet, pcpname, cur_value in self.ts2pcp.itermetrics( i ):
    
                iname = ""
                if "%s:%s:%s" % (type, dev, tmet) in self.dev_inst:
                    iname = self.dev_inst["%s:%s:%s" % (type, dev, tmet)]
    
                var_type = pcpmapping.pcpmappingdict[type][tmet]['type']
                if( int(var_type) == 4): #FLOAT
                    #print "Putting %s %s int(string): %f (%s)" % (pcpname, iname, cur_value,cur_value)
                    self.pcpout.pmiPutValue( pcpname, iname, "%f" % cur_value )
                else:
                    #print "Putting %s %s int(string): %d (%s)" % (pcpname, iname, cur_value,cur_value)
                    self.pcpout.pmiPutValue( pcpname, iname, "%d" % cur_value )
    
            timetuple = math.modf(self.tsreader.times[i])
            useconds = int(timetuple[0] * 1000000)
            seconds = int(timetuple[1])
            self.pcpout.pmiWrite( seconds, useconds)

    def convert(self):

        self.parse_opt()

        self.read_taccstats()

        self.process_taccstats()

        self.init_pcp()

        self.setup_mappings()

        self.write_metrics()

if __name__ == '__main__':
    t2p = TaccStats2PCP( sys.argv )
    t2p.convert()
